{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722b9d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/afroehli/miniconda3/envs/dinov2Pre/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load libs \n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Union \n",
    "from pathlib import Path\n",
    "from torch import device, cuda, hub, mean, no_grad, unbind\n",
    "from tqdm import tqdm\n",
    "\n",
    "from timm.data import resolve_model_data_config, create_transform\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eab77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load general list for wnid to index mapping: Index(wnid) -> pos. in list\n",
    "\n",
    "class_to_index_mapping = []\n",
    "\n",
    "with open('/home/stud/afroehli/coding/dinov2_ood/storage/imagenet_train_class_to_index_mapping.csv', 'r') as class_index_table:\n",
    "    class_index_reader = csv.reader(class_index_table, delimiter=';')\n",
    "    for inet_class, _ in class_index_reader: \n",
    "        class_to_index_mapping.append(inet_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e61aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset where classes are defined by directories + exclude directories from loading by instantiation \n",
    "\n",
    "class CustomizedImageFolder(ImageFolder): \n",
    "\n",
    "    def __init__(self, not_processed_imagenet_classes = None, root = None, transform = None):\n",
    "        self.not_processed_imagenet_classes = not_processed_imagenet_classes \n",
    "        super().__init__(root = root, transform = transform)\n",
    "\n",
    "    def find_classes(self, directory: Union[str, Path]) -> tuple[list[str], dict[str, int]]:\n",
    "\n",
    "        class_list = []\n",
    "        class_index_dict = dict()\n",
    "    \n",
    "        with open('/home/stud/afroehli/coding/dinov2_ood/storage/imagenet_train_class_to_index_mapping.csv', 'r') as class_index_table:\n",
    "\n",
    "            class_index_reader = csv.reader(class_index_table, delimiter=';')\n",
    "            for table_row in class_index_reader:\n",
    "                class_wnid = table_row[0]\n",
    "                class_index = table_row[1]\n",
    "\n",
    "                if class_wnid in self.not_processed_imagenet_classes:\n",
    "                    class_list.append(class_wnid)\n",
    "                    class_index_dict[class_wnid] = class_index\n",
    "\n",
    "        return class_list, class_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1621ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset where classes are defined by directories + exclude directories from loading by instantiation \n",
    "\n",
    "class CustomizedImageFolderForImagenetV2(ImageFolder): \n",
    "\n",
    "    def __init__(self, not_processed_imagenet_classes = None, root = None, transform = None):\n",
    "        self.not_processed_imagenet_classes = not_processed_imagenet_classes \n",
    "        super().__init__(root = root, transform = transform)\n",
    "\n",
    "    def find_classes(self, directory: Union[str, Path]) -> tuple[list[str], dict[str, int]]:\n",
    "\n",
    "        class_list = []\n",
    "        class_index_dict = dict()\n",
    "    \n",
    "        with open('/home/stud/afroehli/coding/dinov2_ood/storage/imagenet_train_class_to_index_mapping.csv', 'r') as class_index_table:\n",
    "            with open('/home/stud/afroehli/datasets/imagenet_v2_label_transform/imagenet_1k_label_order.txt', 'r') as label_order_file:\n",
    "                inet_1k_labels = label_order_file.readlines()\n",
    "                inet_1k_labels = [label_order_line.split()[0] for label_order_line in inet_1k_labels]\n",
    "\n",
    "                class_index_reader = csv.reader(class_index_table, delimiter=';')\n",
    "                for table_row in class_index_reader:\n",
    "                    class_wnid = table_row[0]\n",
    "                    class_index = table_row[1]\n",
    "\n",
    "                    inet_1k_label_pos = inet_1k_labels.index(class_wnid)\n",
    "                    if class_wnid in self.not_processed_imagenet_classes:\n",
    "                        class_list.append(class_wnid)\n",
    "                        class_index_dict[str(inet_1k_label_pos)] = class_index\n",
    "\n",
    "        return class_list, class_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060a3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before change: {'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875, 'crop_mode': 'center'}\n",
      "Following transform will be applied: Compose(\n",
      "    Resize(size=592, interpolation=bicubic, max_size=None, antialias=True)\n",
      "    CenterCrop(size=(518, 518))\n",
      "    MaybeToTensor()\n",
      "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      ")\n",
      "{'input_size': (3, 518, 518), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875, 'crop_mode': 'center'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CustomizedImageFolderForImagenetV2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m inet_r_labels = os.listdir(inet_r_path)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# datasets \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m inet_v2_70 = \u001b[43mCustomizedImageFolderForImagenetV2\u001b[49m(not_processed_imagenet_classes=inet_1k_labels,\n\u001b[32m     30\u001b[39m                                                 root=\u001b[33m'\u001b[39m\u001b[33m/home/stud/afroehli/datasets/ImagenetV2/imagenetv2-threshold0.7-format-val\u001b[39m\u001b[33m'\u001b[39m, transform=transform)\n\u001b[32m     31\u001b[39m inet_v2_mf = CustomizedImageFolderForImagenetV2(not_processed_imagenet_classes=inet_1k_labels,\n\u001b[32m     32\u001b[39m                                                 root=\u001b[33m'\u001b[39m\u001b[33m/home/stud/afroehli/datasets/ImagenetV2/imagenetv2-matched-frequency-format-val\u001b[39m\u001b[33m'\u001b[39m, transform=transform)\n\u001b[32m     33\u001b[39m inet_v2_top = CustomizedImageFolderForImagenetV2(not_processed_imagenet_classes=inet_1k_labels,\n\u001b[32m     34\u001b[39m                                                  root=\u001b[33m'\u001b[39m\u001b[33m/home/stud/afroehli/datasets/ImagenetV2/imagenetv2-top-images-format-val\u001b[39m\u001b[33m'\u001b[39m, transform=transform)\n",
      "\u001b[31mNameError\u001b[39m: name 'CustomizedImageFolderForImagenetV2' is not defined"
     ]
    }
   ],
   "source": [
    "# prepare datasets and dataloaders \n",
    "\n",
    "timm_model = 'vit_small_patch14_dinov2'\n",
    "timm_model_conf = resolve_model_data_config(timm_model)\n",
    "print(f'Before change: {timm_model_conf}')\n",
    "timm_model_conf['input_size'] = (3, 518, 518)\n",
    "\n",
    "timm_transform = create_transform(**timm_model_conf, is_training=False)\n",
    "\n",
    "print(f'Following transform will be applied: {timm_transform}')\n",
    "print(timm_model_conf)\n",
    "\n",
    "transform = timm_transform \n",
    "\n",
    "# old transform\n",
    "# transform = transforms.Compose([transforms.Resize((518, 518)),\n",
    "#                                 transforms.ToTensor()])\n",
    "\n",
    "with open('/home/stud/afroehli/datasets/imagenet_v2_label_transform/imagenet_1k_label_order.txt', 'r') as label_order_file:\n",
    "    inet_1k_labels = label_order_file.readlines()\n",
    "    inet_1k_labels = [label_order_line.split()[0] for label_order_line in inet_1k_labels]\n",
    "\n",
    "inet_r_path = Path('/home/stud/afroehli/datasets/ImagenetR_orig/imagenet-r')\n",
    "inet_r_path.resolve()\n",
    "inet_r_labels = os.listdir(inet_r_path)\n",
    "\n",
    "# datasets \n",
    "\n",
    "inet_v2_70 = CustomizedImageFolderForImagenetV2(not_processed_imagenet_classes=inet_1k_labels,\n",
    "                                                root='/home/stud/afroehli/datasets/ImagenetV2/imagenetv2-threshold0.7-format-val', transform=transform)\n",
    "inet_v2_mf = CustomizedImageFolderForImagenetV2(not_processed_imagenet_classes=inet_1k_labels,\n",
    "                                                root='/home/stud/afroehli/datasets/ImagenetV2/imagenetv2-matched-frequency-format-val', transform=transform)\n",
    "inet_v2_top = CustomizedImageFolderForImagenetV2(not_processed_imagenet_classes=inet_1k_labels,\n",
    "                                                 root='/home/stud/afroehli/datasets/ImagenetV2/imagenetv2-top-images-format-val', transform=transform)\n",
    "\n",
    "inet_1k_val_resized = CustomizedImageFolder(not_processed_imagenet_classes=inet_1k_labels, \n",
    "                                            root='/home/stud/afroehli/datasets/ImageNet1k/imagenet1k/ILSVRC/Data/CLS-LOC/val_sorted', transform=transform)\n",
    "\n",
    "inet_1k_train = CustomizedImageFolder(not_processed_imagenet_classes=inet_1k_labels, root='/home/stud/afroehli/datasets/ImageNet1k/imagenet1k/ILSVRC/Data/CLS-LOC/train', transform=transform)\n",
    "\n",
    "\n",
    "inet_r = CustomizedImageFolder(not_processed_imagenet_classes=inet_r_labels, root=inet_r_path, transform=transform)\n",
    "\n",
    "# dataloader \n",
    "\n",
    "inet_1k_val_loader = DataLoader(dataset=inet_1k_val_resized, shuffle=False, batch_size=128, num_workers=8, pin_memory=True)\n",
    "\n",
    "inet_v2_70_loader = DataLoader(dataset=inet_v2_70, shuffle=False, batch_size=128, num_workers=8, pin_memory=True)\n",
    "\n",
    "inet_v2_mf_loader = DataLoader(dataset=inet_v2_mf, shuffle=False, batch_size=128, num_workers=8, pin_memory=True)\n",
    "\n",
    "inet_v2_top_loader = DataLoader(dataset=inet_v2_top, shuffle=False, batch_size=128, num_workers=8, pin_memory=True)\n",
    "\n",
    "inet_1k_train_loader = DataLoader(dataset=inet_1k_train, shuffle=False, batch_size=128, num_workers=8, pin_memory=True)\n",
    "\n",
    "inet_r_loader = DataLoader(dataset=inet_r, shuffle=False, batch_size=128, num_workers=8, pin_memory=True)\n",
    "\n",
    "print(f'inet-1k: {len(inet_1k_val_resized)}')\n",
    "print(f'inet_v2_70: {len(inet_v2_70)}')\n",
    "print(f'inet_1k_train: {len(inet_1k_train)}')\n",
    "print(f'inet_r: {len(inet_r)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bcafb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/stud/afroehli/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/stud/afroehli/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/stud/afroehli/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/stud/afroehli/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DinoVisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x NestedTensorBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MemEffAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model to be used \n",
    "\n",
    "device = device('cuda' if cuda.is_available() else 'cpu')\n",
    "print(f'Device used: {device}')\n",
    "\n",
    "vision_transformer = hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
    "vision_transformer.eval()\n",
    "vision_transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f505c318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next calculate results for dataset: inet_v2_70_plus_pt_timm_trans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples\n",
      "<class 'tuple'>\n",
      "1\n",
      "<class 'tuple'>\n",
      "2\n",
      "torch.Size([1, 1369, 384])\n",
      "torch.Size([1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/79 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mprint\u001b[39m(sample_out[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m].shape)\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(sample_out[\u001b[32m0\u001b[39m][\u001b[32m1\u001b[39m].shape)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m1\u001b[39m==\u001b[32m0\u001b[39m\n\u001b[32m     35\u001b[39m     batch_out.append(sample_out)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# store [4th layer (mean-patch-tokens, cls-token), 3rd layer ...]\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# compute new embeddings \n",
    "\n",
    "inet_1k_val_loader_tuple = (inet_1k_val_loader, '/home/stud/afroehli/coding/model_results/dinov2_vits14/inet_1k_val_pt_timm_trans.pkl')\n",
    "inet_1k_train_loader_tuple = (inet_1k_train_loader, '/home/stud/afroehli/coding/model_results/dinov2_vits14/inet_1k_train_timm_trans.pkl')\n",
    "inet_v2_70_loader_tuple = (inet_v2_70_loader, '/home/stud/afroehli/coding/model_results/dinov2_vits14/inet_v2_70_plus_pt_timm_trans.pkl')\n",
    "inet_v2_mf_loader_tuple = (inet_v2_mf_loader, '/home/stud/afroehli/coding/model_results/dinov2_vits14/inet_v2_mf_plus_pt_timm_trans.pkl')\n",
    "inet_v2_top_loader_tuple = (inet_v2_top_loader, '/home/stud/afroehli/coding/model_results/dinov2_vits14/inet_v2_top_plus_pt_timm_trans.pkl')\n",
    "inet_r_loader_tuple = (inet_r_loader, '/home/stud/afroehli/coding/model_results/dinov2_vits14/inet_r_plus_pt_timm_trans.pkl')\n",
    "\n",
    "dataloaders = [inet_v2_70_loader_tuple, inet_v2_mf_loader_tuple, inet_v2_top_loader_tuple]\n",
    "\n",
    "with no_grad():\n",
    "\n",
    "    for loader, str_path in dataloaders:\n",
    "            \n",
    "        model_results = dict()\n",
    "\n",
    "        print(f'Next calculate results for dataset: {str_path.split('/')[-1].removesuffix('.pkl')}')\n",
    "\n",
    "        for samples, sample_indices in (pbar := tqdm(loader, ncols=100)):\n",
    "\n",
    "            samples = unbind(samples, dim=0)\n",
    "            # get output of last 4 layers\n",
    "            batch_out = []\n",
    "            for sample in [sample.unsqueeze(0).to(device) for sample in samples]:\n",
    "                sample_out = vision_transformer.get_intermediate_layers(sample, 1, return_class_token=True)\n",
    "                print('Samples')\n",
    "                print(type(sample_out))\n",
    "                print(len(sample_out))\n",
    "                print(type(sample_out[0]))\n",
    "                print(len(sample_out[0]))\n",
    "                print(sample_out[0][0].shape)\n",
    "                print(sample_out[0][1].shape)\n",
    "                assert 1==0\n",
    "                batch_out.append(sample_out)\n",
    "\n",
    "            # store [4th layer (mean-patch-tokens, cls-token), 3rd layer ...]\n",
    "            model_out_converted = []\n",
    "            for sample_out in batch_out:\n",
    "                proc_out = []\n",
    "                for i in range(4):\n",
    "                    pt_tokens = sample_out[i][0]\n",
    "                    cls_token = sample_out[i][1]\n",
    "                    proc_out.append((mean(pt_tokens, dim=1).cpu().detach().numpy(), cls_token.cpu().detach().numpy()))\n",
    "                model_out_converted.append(proc_out)\n",
    "\n",
    "            # transform sample-index to wnid-string\n",
    "            wnid_per_sample = [class_to_index_mapping[int(sample_index)] for sample_index in sample_indices]\n",
    "\n",
    "            for n, sample_out_conv in enumerate(model_out_converted):\n",
    "                sample_item_wnid = wnid_per_sample[n]\n",
    "                try: \n",
    "                    model_results[sample_item_wnid].append(sample_out_conv)\n",
    "                except KeyError:\n",
    "                    model_results[sample_item_wnid] = []\n",
    "                    model_results[sample_item_wnid].append(sample_out_conv)\n",
    "                    \n",
    "\n",
    "        with open(str_path, 'wb') as pkl_file:\n",
    "            pickle.dump(model_results, pkl_file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f3c5cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incomplete classes: 0\n"
     ]
    }
   ],
   "source": [
    "# check if all embeddings have been computed \n",
    "\n",
    "with open('/home/afroehli/datasets/imagenet_v2_label_transform/imagenet_1k_label_order.txt', 'r') as label_order_file:\n",
    "    inet_1k_labels = label_order_file.readlines()\n",
    "    inet_1k_labels = [label_order_line.split()[0] for label_order_line in inet_1k_labels]\n",
    "    \n",
    "with open('/home/afroehli/coding/model_results/dinov2_vits14/inet_1k_train_timm_trans.pkl', 'rb') as pkl_file:\n",
    "    inet_1k_train_model_results = pickle.load(pkl_file)\n",
    "\n",
    "incomplete_classes = 0\n",
    "for wnid in inet_1k_labels:\n",
    "    expec_embeds = len(os.listdir(f'/home/afroehli/datasets/ImageNet1k/imagenet1k/ILSVRC/Data/CLS-LOC/train/{wnid}'))\n",
    "\n",
    "    if expec_embeds != len(inet_1k_train_model_results[wnid]):\n",
    "        incomplete_classes += 1 \n",
    "\n",
    "print(f'Number of incomplete classes: {incomplete_classes}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2Pre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
