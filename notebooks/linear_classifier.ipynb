{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb8b7116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "from torch import hub, device, cuda, load, Tensor, nn, cat, from_numpy, argmax, mean\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from timm.data import resolve_model_data_config, create_transform\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "sys.path.append(r'/home/stud/afroehli/coding/util_scripts')\n",
    "from utils_dataloading.imagenet_tree import ImagenetSemanticInfo, ImagenetSemanticSubtree\n",
    "\n",
    "device = device('cuda' if cuda.is_available() else 'cpu')\n",
    "print(f'Device used: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fd72d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop node discovered\n"
     ]
    }
   ],
   "source": [
    "# util objects\n",
    "\n",
    "imagenet_info = ImagenetSemanticInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0651b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/stud/afroehli/datasets/imagenet_v2_label_transform/imagenet_1k_label_order.txt', 'r') as label_order_file:\n",
    "    inet_1k_labels = label_order_file.readlines()\n",
    "    inet_1k_labels = [label_order_line.split()[0] for label_order_line in inet_1k_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab4b4483",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_a_b_map = dict()\n",
    "\n",
    "with open('/home/stud/afroehli/coding/dinov2_ood/storage/class_a_class_b_timm_trans.csv', 'r') as class_split_table:\n",
    "    closest_pairs_timm_trans = csv.reader(class_split_table, delimiter=';')\n",
    "\n",
    "    for class_a, class_b in closest_pairs_timm_trans:\n",
    "        class_a_b_map[class_a] = class_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb116ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/stud/afroehli/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/stud/afroehli/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/stud/afroehli/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/stud/afroehli/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "/tmp/ipykernel_130415/3623471140.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretr_head = load('/home/stud/afroehli/coding/dinov2_ood/pretrained_heads/dinov2_vits14_linear_head.pth')\n",
      "/tmp/ipykernel_130415/3623471140.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretr_head_big = load('/home/stud/afroehli/coding/dinov2_ood/pretrained_heads/dinov2_vits14_linear4_head.pth')\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "vision_transformer = hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
    "vision_transformer.eval()\n",
    "vision_transformer.to(device)\n",
    "\n",
    "pretr_head = load('/home/stud/afroehli/coding/dinov2_ood/pretrained_heads/dinov2_vits14_linear_head.pth')\n",
    "pretr_head_big = load('/home/stud/afroehli/coding/dinov2_ood/pretrained_heads/dinov2_vits14_linear4_head.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bbee625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 768])\n",
      "torch.Size([1000, 768])\n",
      "torch.Size([1000, 384])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000, 1920])\n",
      "torch.Size([1000])\n",
      "odict_keys(['weight', 'bias'])\n"
     ]
    }
   ],
   "source": [
    "# experiments\n",
    "#print(pretr_head)\n",
    "#summary(pretr_head)\n",
    "print(pretr_head['weight'].size())\n",
    "print(pretr_head['weight'].shape)\n",
    "cls_head = pretr_head['weight'][:,0:384]\n",
    "print(cls_head.shape)\n",
    "print(pretr_head['bias'].size())\n",
    "print(pretr_head_big['weight'].size())\n",
    "print(pretr_head_big['bias'].size())\n",
    "print(pretr_head_big.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bda14ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 518, 518])\n"
     ]
    }
   ],
   "source": [
    "base_path = '/home/stud/afroehli/datasets/ImageNet1k/imagenet1k/ILSVRC/Data/CLS-LOC/val_sorted/n01484850'\n",
    "imgs_pths_one_class = os.listdir(base_path)\n",
    "\n",
    "timm_model = 'vit_small_patch14_dinov2'\n",
    "timm_model_conf = resolve_model_data_config(timm_model)\n",
    "timm_model_conf['input_size'] = (3, 518, 518)\n",
    "\n",
    "timm_transform = create_transform(**timm_model_conf, is_training=False)\n",
    "\n",
    "imgs_transformed = [timm_transform(Image.open(base_path + '/' + img_path)) for img_path in imgs_pths_one_class]\n",
    "\n",
    "print(imgs_transformed[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b860f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LinearClassifier(nn.Module): \n",
    "\n",
    "    def __init__(self, in_features = 384, out_features = 1000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(in_features= in_features, out_features=out_features),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cb198f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 384])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "test_lc = LinearClassifier()\n",
    "\n",
    "print(test_lc.state_dict()['network.0.weight'].size())\n",
    "print(test_lc.state_dict()['network.0.bias'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc34090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1369, 384])\n",
      "torch.Size([1, 384])\n"
     ]
    }
   ],
   "source": [
    "img_on_dev = imgs_transformed[0]\n",
    "img_on_dev = img_on_dev.unsqueeze(0)\n",
    "img_on_dev = img_on_dev.to(device)\n",
    "patch_tokens = vision_transformer.get_intermediate_layers(img_on_dev, return_class_token=True)\n",
    "\n",
    "print(patch_tokens[0][0].shape)\n",
    "print(patch_tokens[0][1].shape)\n",
    "# p_token_cpu = patch_tokens[0].cpu().detach().numpy()\n",
    "# p_token_mean = np.mean(p_token_cpu, axis=1)\n",
    "# print(p_token_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de79edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet for training LinearClassifier\n",
    "# custom dataset: dictonary -> [(embedding, index_as_tensor)]\n",
    "\n",
    "class DictionaryDataset(torch.utils.data.Dataset): \n",
    "    \n",
    "    \"\"\"\n",
    "    Pararms:\n",
    "    1) data: complete dataset provided as dict\n",
    "    2) index_list: list of data_dict-keys, order of keys in list will be used to create a tensor as the expected model-output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: dict, index_list: list[str]): \n",
    "        self.data_dict = data\n",
    "        self.index_list = index_list \n",
    "        self.wnid_list = list(self.data_dict.keys())\n",
    "        self.wnid_iterator = iter(self.wnid_list)\n",
    "        self.instance_per_wnid = [len(self.data_dict[key]) for key in self.wnid_list]\n",
    "\n",
    "    def __len__(self) -> int: \n",
    "        total_len = 0 \n",
    "        for key in self.wnid_list:\n",
    "            total_len += len(self.data_dict[key])\n",
    "\n",
    "        return total_len \n",
    "    \n",
    "    def __getitem__(self, idx) -> tuple[torch.Tensor, torch.Tensor]: \n",
    "\n",
    "        sum_instances = 0\n",
    "        sum_rest = 0\n",
    "\n",
    "        # start with first wnid in list\n",
    "        new_wnid = ''\n",
    "\n",
    "        # iterate until total of all already covered instances is bigger than index of interest\n",
    "        # when class of interest is reached, condition will be false (sum_instances points to first element of next class)\n",
    "        for wnid in self.wnid_list: \n",
    "            if sum_instances > idx:\n",
    "                break \n",
    "            new_wnid = wnid \n",
    "            sum_rest = sum_instances \n",
    "            sum_instances += len(self.data_dict[wnid])\n",
    "\n",
    "        # index within class is needed \n",
    "        # fixed order: [class1, class2, ...]\n",
    "        # when lenght of each previously covered class is known, index within class of interest can be calculated \n",
    "        # sum_rest always represent the total of instances of all covered classes yet, not of interest\n",
    "        idx_within_class = idx - sum_rest\n",
    "\n",
    "        np_arr = self.data_dict[new_wnid][idx_within_class]\n",
    "        data_tensor = torch.tensor(np.array(np_arr))\n",
    "\n",
    "        label_tensor = torch.zeros(len(self.index_list))\n",
    "        # put a one at the position for the expected class \n",
    "        label_tensor[self.index_list.index(new_wnid)] = 1 \n",
    "\n",
    "        return data_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad5bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/stud/afroehli/coding/model_results/dinov2_vits14/inet_1k_val_pt_timm_trans.pkl', 'rb') as pkl_fl:\n",
    "    inet_1k_pt_data = pickle.load(pkl_fl)\n",
    "\n",
    "inet_1k_pt_dataset = DictionaryDataset(data = inet_1k_pt_data, index_list=inet_1k_labels)\n",
    "inet_1k_pt_dataloader = DataLoader(dataset=inet_1k_pt_dataset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a63eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_a_tensor = torch.zeros(len(inet_1k_labels))\n",
    "\n",
    "for class_a_wnid in class_a_b_map.keys():\n",
    "    pos = inet_1k_labels.index(class_a_wnid)\n",
    "    class_a_tensor[pos] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f466e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model LC_ONE_LAYER: 0.81774\n",
      "Accuracy of model LC_CLS_TOKEN: 0.74644\n",
      "Accuracy of model LC_FOUR_LAYER: 0.80774\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_params_one_layer = OrderedDict()\n",
    "model_params_four_layers = OrderedDict()\n",
    "model_params_cls_token = OrderedDict()\n",
    "model_params_one_layer['network.0.weight'] = pretr_head['weight']\n",
    "model_params_one_layer['network.0.bias'] = pretr_head['bias']\n",
    "model_params_cls_token['network.0.weight'] = pretr_head['weight'][:,0:384]\n",
    "model_params_cls_token['network.0.bias'] = pretr_head['bias']\n",
    "model_params_four_layers['network.0.weight'] = pretr_head_big['weight']\n",
    "model_params_four_layers['network.0.bias'] = pretr_head_big['bias']\n",
    "\n",
    "lc_one_layer = LinearClassifier(in_features=768, out_features=1000)\n",
    "lc_cls_token = LinearClassifier(in_features=384, out_features=1000)\n",
    "lc_four_layer = LinearClassifier(in_features=1920, out_features=1000)\n",
    "\n",
    "lc_one_layer.load_state_dict(model_params_one_layer)\n",
    "lc_cls_token.load_state_dict(model_params_cls_token)\n",
    "lc_four_layer.load_state_dict(model_params_four_layers)\n",
    "\n",
    "lc_one_layer.eval()\n",
    "lc_cls_token.eval()\n",
    "lc_four_layer.eval()\n",
    "\n",
    "lc_one_layer.to(device)\n",
    "lc_cls_token.to(device)\n",
    "lc_four_layer.to(device)\n",
    "\n",
    "acc_per_class = dict()\n",
    "\n",
    "# for each lc calculate accuracy on INet-1k Val \n",
    "\n",
    "with torch.no_grad():\n",
    "    for lc_model, lc_name in [(lc_one_layer, 'LC_ONE_LAYER'), (lc_cls_token, 'LC_CLS_TOKEN'), (lc_four_layer, 'LC_FOUR_LAYER')]:\n",
    "\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        pred_arr = []\n",
    "        label_arr = []\n",
    "\n",
    "        acc_per_class[lc_name] = dict()\n",
    "        for class_a_wnid in class_a_b_map.keys():\n",
    "            acc_per_class[lc_name][class_a_wnid] = {'true_pred': 0, 'total_pred': 0, 'acc': 0, 'm_smax': np.zeros(1000)}\n",
    "\n",
    "        for batch in inet_1k_pt_dataloader:\n",
    "            \n",
    "            batch_samples = batch[0]\n",
    "            batch_labels = batch[1]\n",
    "            if lc_name == 'LC_ONE_LAYER':\n",
    "                batch_samples_dev = cat([cat((batch_sample[3][1].squeeze(), batch_sample[3][0].squeeze())).unsqueeze(0)\n",
    "                                    for batch_sample in batch_samples]).to(device)\n",
    "            elif lc_name == 'LC_CLS_TOKEN':\n",
    "                batch_samples_dev = cat([batch_sample[3][1] for batch_sample in batch_samples]).to(device)\n",
    "            elif lc_name == 'LC_FOUR_LAYER':\n",
    "                batch_samples_dev = cat([cat(((cat([cls_token for _, cls_token in batch_sample], dim=-1),\n",
    "                    batch_sample[3][0])), dim=-1)\n",
    "                    for batch_sample in batch_samples]).to(device)\n",
    "            else:\n",
    "                raise ValueError(f'Name of lc not defined: {lc_name}')\n",
    "            \n",
    "            lc_preds = lc_model(batch_samples_dev)\n",
    "            lc_preds = lc_preds.cpu()\n",
    "            is_equal = batch_labels.argmax(axis=1) == lc_preds.argmax(axis=1) \n",
    "            correct_preds += is_equal.type(torch.float).sum().item()\n",
    "            total_preds += is_equal.size(0)\n",
    "            \n",
    "            # detect class_a examples by label \n",
    "            for i in range(0, batch_labels.shape[0]):\n",
    "                is_class_a = torch.logical_and(batch_labels[i, :], class_a_tensor).nonzero()\n",
    "                if is_class_a.numel() == True:\n",
    "                    matching_index = is_class_a[0].item()\n",
    "                    matching_wnid = inet_1k_labels[matching_index]\n",
    "                    if is_equal[i].item(): \n",
    "                        acc_per_class[lc_name][matching_wnid]['true_pred'] += 1\n",
    "                    acc_per_class[lc_name][matching_wnid]['total_pred'] += 1\n",
    "                    acc_per_class[lc_name][matching_wnid]['m_smax'] = acc_per_class[lc_name][matching_wnid]['m_smax'] + np.array(lc_preds[i])\n",
    "\n",
    "            pred_arr.append(lc_preds)\n",
    "            label_arr.append(batch_labels)\n",
    "\n",
    "        acc_model = correct_preds / total_preds \n",
    "        print(f'Accuracy of model {lc_name}: {acc_model}')\n",
    "\n",
    "        for class_a_wnid in class_a_b_map.keys():\n",
    "            acc_per_class[lc_name][class_a_wnid]['acc'] = float(acc_per_class[lc_name][class_a_wnid]['true_pred']) / 50\n",
    "            acc_per_class[lc_name][class_a_wnid]['m_smax'] = acc_per_class[lc_name][class_a_wnid]['m_smax'] / 50\n",
    "            \n",
    "        #sk_acc = accuracy_score(label_arr, [p_acc.cpu() for p_acc in pred_arr], normalize=True)\n",
    "        #print(f'SK acc: {sk_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a731c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-A:  strawberry, Max-4: [' pineapple', ' pomegranate', ' trifle', ' strawberry']\n",
      "Class-A:  peafowl, Max-4: [' spider web', ' macaw', ' quill', ' peafowl']\n",
      "Class-A:  Labrador Retriever, Max-4: [' tennis ball', ' Flat-Coated Retriever', ' Golden Retriever', ' Labrador Retriever']\n",
      "Class-A:  monarch butterfly, Max-4: [' cardoon', ' lemon', ' red admiral butterfly', ' monarch butterfly']\n",
      "Class-A:  giant panda, Max-4: [' soap dispenser', ' badger', ' teddy bear', ' giant panda']\n"
     ]
    }
   ],
   "source": [
    "class_a_wnids = list(class_a_b_map.keys())\n",
    "class_a_test = class_a_wnids[0:5]\n",
    "\n",
    "\n",
    "for class_a in class_a_test:\n",
    "\n",
    "    sorted_smax = np.argsort(acc_per_class['LC_ONE_LAYER'][class_a]['m_smax'])\n",
    "    print(f'Class-A: {imagenet_info.wnid_to_classname[class_a]}, Max-4: {[imagenet_info.wnid_to_classname[inet_1k_labels[pos.item()]] for pos in sorted_smax[-4:]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6deb72c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each class-a mean softmax \n",
    "\n",
    "# calculate diffs: class-a -> class-b, class-a -> nearest class not class-b \n",
    "\n",
    "softmax_diffs = dict()\n",
    "\n",
    "wrong_max_sm = []\n",
    "\n",
    "for class_a_wnid in class_a_b_map.keys():\n",
    "\n",
    "    softmax_diffs[class_a_wnid] = {'class_b_diff': [tuple], 'next_class_diff': [tuple]}\n",
    "\n",
    "    class_b_wnid = class_a_b_map[class_a_wnid]\n",
    "    class_a_index = inet_1k_labels.index(class_a_wnid)\n",
    "    class_b_index = inet_1k_labels.index(class_b_wnid)\n",
    "\n",
    "    class_a_sm = acc_per_class['LC_ONE_LAYER'][class_a_wnid]['m_smax']\n",
    "    class_a_sm_val = class_a_sm[inet_1k_labels.index(class_a_wnid)]\n",
    "    sm_arr_class_a_val = np.array([class_a_sm_val for i in range(1000)])\n",
    "    diff_to_class_a_val = np.subtract(sm_arr_class_a_val, class_a_sm) \n",
    "\n",
    "    diff_b_val = diff_to_class_a_val[inet_1k_labels.index(class_b_wnid)]\n",
    "    softmax_diffs[class_a_wnid]['class_b_diff'] = (class_b_wnid, diff_b_val) \n",
    "\n",
    "    min_diff_indices = np.argsort(diff_to_class_a_val)\n",
    "\n",
    "    for min_diff_index in min_diff_indices:\n",
    "        if not min_diff_index in [class_a_index, class_b_index]: \n",
    "            # print(inet_1k_labels[min_diff_index])\n",
    "            # print(f'Next class: {imagenet_info.wnid_to_classname[inet_1k_labels[min_diff_index]]}')\n",
    "            next_lowest_diff = diff_to_class_a_val[min_diff_index]\n",
    "            \n",
    "            next_class_wnid = inet_1k_labels[min_diff_index]\n",
    "            softmax_diffs[class_a_wnid]['next_class_diff'] = (next_class_wnid, next_lowest_diff)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc3de7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate l1-distances for class-b and next_nearest-class to class-a \n",
    "\n",
    "comp_l1_dists = dict()\n",
    "\n",
    "with open('/home/stud/afroehli/coding/dinov2_ood/storage/class_a_b_next_nearest.csv', 'r') as csv_file:\n",
    "    with open('/home/stud/afroehli/coding/model_results/dinov2_vits14/inet_1k_val_timm_trans.pkl', 'rb') as pkl_fl: \n",
    "\n",
    "        inet_1k_val_res = pickle.load(pkl_fl)\n",
    "\n",
    "        csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "        for n, (class_a_wnid, class_b_wnid, nn_class_wnid) in enumerate(csv_reader):\n",
    "            if n != 0: \n",
    "                class_a_mean_emb = np.mean(inet_1k_val_res[class_a_wnid], axis=0)\n",
    "                class_b_mean_emb = np.mean(inet_1k_val_res[class_b_wnid], axis=0)\n",
    "                nn_class_mean_emb = np.mean(inet_1k_val_res[nn_class_wnid], axis=0)\n",
    "\n",
    "\n",
    "                comp_l1_dists[class_a_wnid] = {'class_b': np.sum(np.abs(class_a_mean_emb - class_b_mean_emb)), \n",
    "                                               'nn_class': np.sum(np.abs(class_a_mean_emb - nn_class_mean_emb))}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97d4d746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for class_a in comp_l1_dists.keys():\n",
    "    x_data.append((comp_l1_dists[class_a]['class_b'] / comp_l1_dists[class_a]['nn_class']).item())\n",
    "    y_data.append((softmax_diffs[class_a]['class_b_diff'][1] / softmax_diffs[class_a]['next_class_diff'][1]).item())\n",
    "\n",
    "sns.scatterplot(x=x_data, y=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3840668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results for softmax-diff in csv-file \n",
    "\n",
    "with open('/home/stud/afroehli/coding/dinov2_ood/storage/softmax_diffs.csv', 'w', newline='') as csv_fl: \n",
    "    csv_writer = csv.writer(csv_fl, delimiter=';')\n",
    "    csv_writer.writerow(['Class-A', 'Class-B', 'Diff-CB', 'Class-Next', 'Diff-CN'])\n",
    "\n",
    "    for class_a_wnid in softmax_diffs.keys():\n",
    "        next_row = [imagenet_info.wnid_to_classname[class_a_wnid], \n",
    "                    imagenet_info.wnid_to_classname[softmax_diffs[class_a_wnid]['class_b_diff'][0]],\n",
    "                    softmax_diffs[class_a_wnid]['class_b_diff'][1], \n",
    "                    imagenet_info.wnid_to_classname[softmax_diffs[class_a_wnid]['next_class_diff'][0]],\n",
    "                    softmax_diffs[class_a_wnid]['next_class_diff'][1]]\n",
    "        csv_writer.writerow(next_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f7d78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC_ONE_LAYER\n",
      "[(0.38, ' bathtub'), (0.44, ' mushroom'), (0.52, ' Toy Poodle'), (0.54, ' vase'), (0.54, ' Bloodhound'), (0.58, ' backpack'), (0.58, ' Siberian Husky'), (0.6, ' Border Collie'), (0.6, ' cauldron'), (0.6, ' flute'), (0.62, ' missile'), (0.64, ' grasshopper'), (0.64, ' red fox'), (0.64, ' hatchet'), (0.64, ' bucket'), (0.64, ' assault rifle'), (0.64, ' cowboy hat'), (0.66, ' smooth newt'), (0.68, ' wine bottle'), (0.68, ' grand piano'), (0.7, ' candle'), (0.7, ' shield'), (0.7, ' tabby cat'), (0.7, ' hammer'), (0.72, ' spider web'), (0.72, ' espresso'), (0.72, ' pig'), (0.72, ' lighthouse'), (0.72, ' ambulance'), (0.74, ' electric guitar'), (0.74, ' lipstick'), (0.74, ' beer glass'), (0.76, ' tank'), (0.76, ' collie'), (0.76, ' Chihuahua'), (0.76, ' pickup truck'), (0.76, ' eel'), (0.78, ' German Shepherd Dog'), (0.78, ' violin'), (0.78, ' ice cream'), (0.78, ' Yorkshire Terrier'), (0.78, ' Shih Tzu'), (0.8, ' cucumber'), (0.8, ' tennis ball'), (0.8, ' lemon'), (0.8, ' Scottish Terrier'), (0.8, ' leopard'), (0.8, ' tractor'), (0.8, ' schooner'), (0.8, ' saxophone'), (0.8, ' baseball player'), (0.82, ' broom'), (0.82, ' mailbox'), (0.82, ' cottontail rabbit'), (0.82, ' wheelbarrow'), (0.82, ' gazelle'), (0.82, ' mobile phone'), (0.84, ' lab coat'), (0.84, ' binoculars'), (0.84, ' bow tie'), (0.84, ' grey wolf'), (0.84, ' rugby ball'), (0.84, ' castle'), (0.84, ' Granny Smith apple'), (0.84, ' scuba diver'), (0.84, ' gibbon'), (0.84, ' mitten'), (0.84, ' Boston Terrier'), (0.86, ' strawberry'), (0.86, ' Beagle'), (0.86, ' dragonfly'), (0.86, ' harmonica'), (0.86, ' ant'), (0.86, ' Golden Retriever'), (0.86, ' beaver'), (0.86, ' volcano'), (0.86, ' pirate ship'), (0.86, ' great white shark'), (0.86, ' birdhouse'), (0.88, ' Pembroke Welsh Corgi'), (0.88, ' scarf'), (0.88, ' sandal'), (0.88, ' hen'), (0.88, ' bee'), (0.88, ' Whippet'), (0.88, ' Boxer'), (0.9, ' Labrador Retriever'), (0.9, ' Cocker Spaniel'), (0.9, ' snail'), (0.9, ' pizza'), (0.9, ' joystick'), (0.9, ' trombone'), (0.9, ' cockroach'), (0.9, ' jeep'), (0.9, ' gorilla'), (0.9, ' starfish'), (0.9, ' Basset Hound'), (0.9, ' cannon'), (0.9, ' American lobster'), (0.9, ' chameleon'), (0.9, ' meerkat'), (0.9, ' banana'), (0.92, ' Rottweiler'), (0.92, ' hot dog'), (0.92, ' revolver'), (0.92, ' centipede'), (0.92, ' space shuttle'), (0.92, ' pretzel'), (0.92, ' guinea pig'), (0.92, ' bagel'), (0.92, ' gas mask or respirator'), (0.92, ' green iguana'), (0.92, ' broccoli'), (0.92, ' military aircraft'), (0.94, ' orangutan'), (0.94, ' soccer ball'), (0.94, ' fly'), (0.94, ' grey whale'), (0.94, ' snow leopard'), (0.94, ' chimpanzee'), (0.94, ' West Highland White Terrier'), (0.94, ' hyena'), (0.94, ' Standard Poodle'), (0.94, ' clownfish'), (0.94, ' polar bear'), (0.94, ' lawn mower'), (0.94, ' guillotine'), (0.94, ' fire truck'), (0.94, ' tree frog'), (0.94, ' cabbage'), (0.94, ' Indian cobra'), (0.94, ' toucan'), (0.94, ' Chow Chow'), (0.94, ' goose'), (0.96, ' giant panda'), (0.96, ' cheetah'), (0.96, ' tiger'), (0.96, ' praying mantis'), (0.96, ' porcupine'), (0.96, ' badger'), (0.96, ' burrito'), (0.96, ' goldfish'), (0.96, ' great egret'), (0.96, ' barn'), (0.96, ' fox squirrel'), (0.96, ' baboon'), (0.96, ' St. Bernard'), (0.96, ' jellyfish'), (0.96, ' hermit crab'), (0.96, ' ladybug'), (0.96, ' stingray'), (0.96, ' tarantula'), (0.96, ' hummingbird'), (0.96, ' Dalmatian'), (0.96, ' hammerhead shark'), (0.96, ' pomegranate'), (0.96, ' school bus'), (0.96, ' bell pepper'), (0.96, ' cheeseburger'), (0.96, ' koala'), (0.96, ' duck'), (0.98, ' monarch butterfly'), (0.98, ' skunk'), (0.98, ' canoe'), (0.98, ' llama'), (0.98, ' parachute'), (0.98, ' pufferfish'), (0.98, ' zebra'), (0.98, ' accordion'), (0.98, ' acorn'), (0.98, ' black swan'), (0.98, ' vulture'), (0.98, ' Weimaraner'), (0.98, ' submarine'), (0.98, ' bison'), (0.98, ' French Bulldog'), (0.98, ' axolotl'), (0.98, ' harp'), (0.98, ' Afghan Hound'), (0.98, ' killer whale'), (0.98, ' Italian Greyhound'), (0.98, ' basketball'), (1.0, ' peafowl'), (1.0, ' sea lion'), (1.0, ' junco'), (1.0, ' lion'), (1.0, ' hippopotamus'), (1.0, ' bald eagle'), (1.0, ' lorikeet'), (1.0, ' flamingo'), (1.0, ' Pomeranian'), (1.0, ' pug'), (1.0, ' pelican'), (1.0, ' pineapple'), (1.0, ' scorpion'), (1.0, ' king penguin'), (1.0, ' ostrich'), (1.0, ' carousel'), (1.0, ' steam locomotive'), (1.0, ' goldfinch')]\n",
      "LC_CLS_TOKEN\n",
      "[(0.04, ' bee'), (0.3, ' vase'), (0.3, ' cowboy hat'), (0.32, ' bucket'), (0.34, ' collie'), (0.34, ' mushroom'), (0.36, ' bathtub'), (0.36, ' smooth newt'), (0.4, ' scarf'), (0.44, ' Border Collie'), (0.44, ' military aircraft'), (0.46, ' pickup truck'), (0.5, ' backpack'), (0.52, ' lab coat'), (0.52, ' leopard'), (0.52, ' tabby cat'), (0.54, ' cauldron'), (0.54, ' Chihuahua'), (0.54, ' gazelle'), (0.56, ' missile'), (0.56, ' wine bottle'), (0.56, ' red fox'), (0.56, ' Siberian Husky'), (0.58, ' spider web'), (0.6, ' candle'), (0.6, ' flute'), (0.6, ' shield'), (0.6, ' castle'), (0.62, ' espresso'), (0.62, ' assault rifle'), (0.62, ' Bloodhound'), (0.62, ' Toy Poodle'), (0.62, ' hammer'), (0.62, ' Yorkshire Terrier'), (0.64, ' tank'), (0.64, ' tennis ball'), (0.64, ' pig'), (0.64, ' ambulance'), (0.66, ' wheelbarrow'), (0.68, ' strawberry'), (0.68, ' binoculars'), (0.68, ' bow tie'), (0.68, ' hatchet'), (0.68, ' scuba diver'), (0.7, ' cucumber'), (0.72, ' ant'), (0.72, ' schooner'), (0.74, ' ice cream'), (0.74, ' hen'), (0.74, ' beer glass'), (0.74, ' eel'), (0.74, ' Boston Terrier'), (0.76, ' lemon'), (0.76, ' Cocker Spaniel'), (0.76, ' birdhouse'), (0.76, ' Shih Tzu'), (0.78, ' German Shepherd Dog'), (0.78, ' sandal'), (0.78, ' electric guitar'), (0.78, ' broom'), (0.78, ' grasshopper'), (0.78, ' cottontail rabbit'), (0.78, ' lighthouse'), (0.78, ' mobile phone'), (0.8, ' soccer ball'), (0.8, ' snail'), (0.8, ' grand piano'), (0.8, ' beaver'), (0.82, ' violin'), (0.82, ' Scottish Terrier'), (0.82, ' fly'), (0.82, ' lipstick'), (0.82, ' Golden Retriever'), (0.82, ' ladybug'), (0.82, ' saxophone'), (0.84, ' Beagle'), (0.84, ' dragonfly'), (0.84, ' grey whale'), (0.84, ' mailbox'), (0.84, ' cockroach'), (0.84, ' Granny Smith apple'), (0.84, ' American lobster'), (0.86, ' Labrador Retriever'), (0.86, ' harmonica'), (0.86, ' bagel'), (0.86, ' volcano'), (0.86, ' cabbage'), (0.86, ' chameleon'), (0.86, ' Boxer'), (0.86, ' goose'), (0.88, ' grey wolf'), (0.88, ' trombone'), (0.88, ' tractor'), (0.88, ' Standard Poodle'), (0.88, ' gorilla'), (0.88, ' Whippet'), (0.88, ' gibbon'), (0.88, ' baseball player'), (0.88, ' mitten'), (0.88, ' great white shark'), (0.88, ' banana'), (0.9, ' revolver'), (0.9, ' fox squirrel'), (0.9, ' Basset Hound'), (0.9, ' lawn mower'), (0.9, ' cannon'), (0.9, ' fire truck'), (0.9, ' Indian cobra'), (0.9, ' broccoli'), (0.92, ' monarch butterfly'), (0.92, ' badger'), (0.92, ' hot dog'), (0.92, ' barn'), (0.92, ' jeep'), (0.92, ' hummingbird'), (0.92, ' starfish'), (0.92, ' pretzel'), (0.92, ' green iguana'), (0.92, ' pirate ship'), (0.92, ' Chow Chow'), (0.92, ' basketball'), (0.94, ' orangutan'), (0.94, ' Rottweiler'), (0.94, ' goldfish'), (0.94, ' great egret'), (0.94, ' snow leopard'), (0.94, ' pizza'), (0.94, ' joystick'), (0.94, ' chimpanzee'), (0.94, ' guinea pig'), (0.94, ' killer whale'), (0.94, ' guillotine'), (0.94, ' gas mask or respirator'), (0.94, ' meerkat'), (0.94, ' toucan'), (0.94, ' duck'), (0.96, ' Pembroke Welsh Corgi'), (0.96, ' cheetah'), (0.96, ' tiger'), (0.96, ' canoe'), (0.96, ' porcupine'), (0.96, ' submarine'), (0.96, ' rugby ball'), (0.96, ' baboon'), (0.96, ' St. Bernard'), (0.96, ' French Bulldog'), (0.96, ' hyena'), (0.96, ' space shuttle'), (0.96, ' hammerhead shark'), (0.96, ' polar bear'), (0.96, ' school bus'), (0.96, ' bell pepper'), (0.96, ' tree frog'), (0.96, ' cheeseburger'), (0.96, ' koala'), (0.98, ' giant panda'), (0.98, ' skunk'), (0.98, ' praying mantis'), (0.98, ' llama'), (0.98, ' parachute'), (0.98, ' sea lion'), (0.98, ' pufferfish'), (0.98, ' zebra'), (0.98, ' accordion'), (0.98, ' acorn'), (0.98, ' burrito'), (0.98, ' vulture'), (0.98, ' bison'), (0.98, ' West Highland White Terrier'), (0.98, ' pineapple'), (0.98, ' hermit crab'), (0.98, ' harp'), (0.98, ' clownfish'), (0.98, ' centipede'), (0.98, ' Afghan Hound'), (0.98, ' Dalmatian'), (0.98, ' king penguin'), (0.98, ' Italian Greyhound'), (1.0, ' peafowl'), (1.0, ' junco'), (1.0, ' black swan'), (1.0, ' lion'), (1.0, ' Weimaraner'), (1.0, ' hippopotamus'), (1.0, ' bald eagle'), (1.0, ' lorikeet'), (1.0, ' flamingo'), (1.0, ' Pomeranian'), (1.0, ' pug'), (1.0, ' jellyfish'), (1.0, ' pelican'), (1.0, ' axolotl'), (1.0, ' stingray'), (1.0, ' tarantula'), (1.0, ' scorpion'), (1.0, ' pomegranate'), (1.0, ' ostrich'), (1.0, ' carousel'), (1.0, ' steam locomotive'), (1.0, ' goldfinch')]\n",
      "LC_FOUR_LAYER\n",
      "[(0.32, ' bathtub'), (0.38, ' missile'), (0.38, ' mushroom'), (0.4, ' Border Collie'), (0.48, ' Toy Poodle'), (0.52, ' backpack'), (0.52, ' cowboy hat'), (0.52, ' Siberian Husky'), (0.54, ' grasshopper'), (0.56, ' wine bottle'), (0.56, ' hatchet'), (0.56, ' Bloodhound'), (0.58, ' spider web'), (0.6, ' cauldron'), (0.6, ' red fox'), (0.62, ' flute'), (0.62, ' bucket'), (0.62, ' hammer'), (0.64, ' vase'), (0.64, ' tabby cat'), (0.66, ' espresso'), (0.66, ' ice cream'), (0.66, ' wheelbarrow'), (0.68, ' candle'), (0.68, ' Chihuahua'), (0.68, ' pig'), (0.7, ' shield'), (0.7, ' smooth newt'), (0.7, ' lighthouse'), (0.72, ' beer glass'), (0.72, ' tractor'), (0.74, ' strawberry'), (0.74, ' electric guitar'), (0.74, ' grey wolf'), (0.74, ' broom'), (0.74, ' grand piano'), (0.74, ' Yorkshire Terrier'), (0.76, ' lipstick'), (0.76, ' castle'), (0.76, ' cottontail rabbit'), (0.76, ' eel'), (0.76, ' Shih Tzu'), (0.78, ' German Shepherd Dog'), (0.78, ' tennis ball'), (0.78, ' Scottish Terrier'), (0.78, ' schooner'), (0.78, ' saxophone'), (0.78, ' baseball player'), (0.78, ' mitten'), (0.8, ' collie'), (0.8, ' rugby ball'), (0.8, ' trombone'), (0.8, ' assault rifle'), (0.8, ' gas mask or respirator'), (0.82, ' Pembroke Welsh Corgi'), (0.82, ' tank'), (0.82, ' violin'), (0.82, ' lemon'), (0.82, ' Cocker Spaniel'), (0.82, ' bow tie'), (0.82, ' ant'), (0.82, ' gazelle'), (0.82, ' banana'), (0.82, ' Boxer'), (0.84, ' cucumber'), (0.84, ' snow leopard'), (0.84, ' pickup truck'), (0.84, ' scuba diver'), (0.84, ' beaver'), (0.84, ' ambulance'), (0.84, ' meerkat'), (0.84, ' mobile phone'), (0.86, ' Beagle'), (0.86, ' binoculars'), (0.86, ' mailbox'), (0.86, ' Granny Smith apple'), (0.86, ' Whippet'), (0.86, ' space shuttle'), (0.86, ' green iguana'), (0.86, ' volcano'), (0.86, ' tree frog'), (0.86, ' pirate ship'), (0.86, ' birdhouse'), (0.86, ' military aircraft'), (0.88, ' Labrador Retriever'), (0.88, ' tiger'), (0.88, ' fly'), (0.88, ' harmonica'), (0.88, ' bee'), (0.88, ' great egret'), (0.88, ' leopard'), (0.88, ' chimpanzee'), (0.88, ' pug'), (0.88, ' cockroach'), (0.88, ' gorilla'), (0.88, ' Basset Hound'), (0.88, ' bagel'), (0.88, ' gibbon'), (0.88, ' fire truck'), (0.88, ' American lobster'), (0.9, ' giant panda'), (0.9, ' scarf'), (0.9, ' lab coat'), (0.9, ' sandal'), (0.9, ' hen'), (0.9, ' dragonfly'), (0.9, ' snail'), (0.9, ' Golden Retriever'), (0.9, ' joystick'), (0.9, ' hummingbird'), (0.9, ' clownfish'), (0.9, ' lawn mower'), (0.9, ' great white shark'), (0.9, ' chameleon'), (0.9, ' broccoli'), (0.92, ' orangutan'), (0.92, ' Rottweiler'), (0.92, ' revolver'), (0.92, ' pizza'), (0.92, ' hyena'), (0.92, ' jeep'), (0.92, ' Standard Poodle'), (0.92, ' starfish'), (0.92, ' centipede'), (0.92, ' hammerhead shark'), (0.92, ' pretzel'), (0.92, ' guinea pig'), (0.92, ' cannon'), (0.92, ' Boston Terrier'), (0.92, ' Indian cobra'), (0.94, ' monarch butterfly'), (0.94, ' cheetah'), (0.94, ' praying mantis'), (0.94, ' sea lion'), (0.94, ' pufferfish'), (0.94, ' hot dog'), (0.94, ' barn'), (0.94, ' submarine'), (0.94, ' St. Bernard'), (0.94, ' French Bulldog'), (0.94, ' West Highland White Terrier'), (0.94, ' ladybug'), (0.94, ' polar bear'), (0.94, ' school bus'), (0.94, ' koala'), (0.94, ' toucan'), (0.94, ' Chow Chow'), (0.94, ' goose'), (0.94, ' duck'), (0.96, ' soccer ball'), (0.96, ' grey whale'), (0.96, ' accordion'), (0.96, ' badger'), (0.96, ' burrito'), (0.96, ' goldfish'), (0.96, ' fox squirrel'), (0.96, ' baboon'), (0.96, ' hermit crab'), (0.96, ' axolotl'), (0.96, ' stingray'), (0.96, ' Afghan Hound'), (0.96, ' Dalmatian'), (0.96, ' pomegranate'), (0.96, ' killer whale'), (0.96, ' bell pepper'), (0.96, ' cheeseburger'), (0.96, ' cabbage'), (0.98, ' skunk'), (0.98, ' llama'), (0.98, ' parachute'), (0.98, ' porcupine'), (0.98, ' zebra'), (0.98, ' acorn'), (0.98, ' black swan'), (0.98, ' vulture'), (0.98, ' lion'), (0.98, ' Weimaraner'), (0.98, ' bison'), (0.98, ' bald eagle'), (0.98, ' jellyfish'), (0.98, ' pineapple'), (0.98, ' harp'), (0.98, ' tarantula'), (0.98, ' scorpion'), (0.98, ' guillotine'), (0.98, ' steam locomotive'), (0.98, ' Italian Greyhound'), (1.0, ' peafowl'), (1.0, ' canoe'), (1.0, ' junco'), (1.0, ' hippopotamus'), (1.0, ' lorikeet'), (1.0, ' flamingo'), (1.0, ' Pomeranian'), (1.0, ' pelican'), (1.0, ' king penguin'), (1.0, ' ostrich'), (1.0, ' carousel'), (1.0, ' basketball'), (1.0, ' goldfinch')]\n"
     ]
    }
   ],
   "source": [
    "lc_one_layer_acc = []\n",
    "lc_only_cls_acc = []\n",
    "lc_four_layer_acc = []\n",
    "\n",
    "for acc_list, lc_name in [(lc_one_layer_acc, 'LC_ONE_LAYER'), (lc_only_cls_acc, 'LC_CLS_TOKEN'), (lc_four_layer_acc, 'LC_FOUR_LAYER')]: \n",
    "    for class_a_wnid in class_a_b_map.keys():\n",
    "        acc_list.append((acc_per_class[lc_name][class_a_wnid]['acc'], imagenet_info.wnid_to_classname[class_a_wnid]))\n",
    "\n",
    "    print(lc_name)\n",
    "    acc_list.sort(key=lambda x: x[0])\n",
    "    print(acc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all class-a instances create dataset and dataloader \n",
    "\n",
    "for class_a in class_a_b_map.keys():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29284bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 3, 2, 2, 2, 148, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 149, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img in imgs_transformed: \n",
    "\n",
    "        last_layer = vision_transformer.get_intermediate_layers(img.unsqueeze(0).to(device), 1, return_class_token=True)\n",
    "        m_pts = mean(last_layer[0][0], dim=1)\n",
    "        comb_tensor = cat((last_layer[0][1].squeeze(),mean(last_layer[0][0], dim=1).squeeze())).unsqueeze(0).to(device)\n",
    "        pred = lc_one_layer(comb_tensor)\n",
    "        preds.append(pred.argmax(axis=1))\n",
    "\n",
    "    print([scal.item() for scal in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a12fd628",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgs_transformed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m l4_layers = vision_transformer.get_intermediate_layers(\u001b[43mimgs_transformed\u001b[49m[\u001b[32m0\u001b[39m].unsqueeze(\u001b[32m0\u001b[39m).to(device), \u001b[32m4\u001b[39m, return_class_token=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(l4_layers))\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m4\u001b[39m):\n",
      "\u001b[31mNameError\u001b[39m: name 'imgs_transformed' is not defined"
     ]
    }
   ],
   "source": [
    "l4_layers = vision_transformer.get_intermediate_layers(imgs_transformed[0].unsqueeze(0).to(device), 4, return_class_token=True)\n",
    "print(len(l4_layers))\n",
    "for i in range(4):\n",
    "    print(f'{i}: Layer')\n",
    "    print(l4_layers[i][0].shape)\n",
    "    print(l4_layers[i][1].shape)\n",
    "\n",
    "output = cat([class_token for _, class_token in l4_layers], dim=-1)\n",
    "print(output.shape)\n",
    "if True:\n",
    "        output = cat(\n",
    "            (\n",
    "                output,\n",
    "                mean(l4_layers[-1][0], dim=1),  # patch tokens\n",
    "            ),\n",
    "            dim=-1,\n",
    "        )\n",
    "print(output.shape)\n",
    "output = output.reshape(output.shape[0], -1)\n",
    "print(output.shape)\n",
    "\n",
    "single_layer = vision_transformer.get_intermediate_layers(imgs_transformed[0].unsqueeze(0).to(device), 0, return_class_token=True)\n",
    "print(single_layer)\n",
    "print(mean(single_layer[0][0], dim=1))\n",
    "print(mean(l4_layers[-1][0], dim=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2Pre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
