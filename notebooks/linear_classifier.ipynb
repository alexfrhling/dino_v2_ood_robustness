{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8b7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "from dinov2_ood_utilities.imagenet_tree import ImagenetSemanticInfo, ImagenetSemanticSubtree\n",
    "from dinov2_ood_utilities.custom_datasets import DictionaryDataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b54081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    }
   ],
   "source": [
    "# define device to use\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device used: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9fd72d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop node discovered\n"
     ]
    }
   ],
   "source": [
    "# util objects\n",
    "\n",
    "imagenet_info = ImagenetSemanticInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0651b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resources/imagenet_1k_label_order.txt', 'r') as label_order_file:\n",
    "    inet_1k_labels = label_order_file.readlines()\n",
    "    inet_1k_labels = [label_order_line.split()[0] for label_order_line in inet_1k_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb116ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2299079/2118242824.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretr_head = torch.load('../resources/pretrained_heads/dinov2_vits14_linear_head.pth')\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "pretr_head = torch.load('../resources/pretrained_heads/dinov2_vits14_linear_head.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b860f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LinearClassifier(nn.Module): \n",
    "\n",
    "    def __init__(self, in_features = 384, out_features = 1000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(in_features= in_features, out_features=out_features),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bad5bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders for INet-1k-Val, INet-R, INet-V2\n",
    "\n",
    "dataloaders_dict = dict()\n",
    "\n",
    "for loader_name, loader_path in [('inet_1k_val', '../resources/vit_s_embeddings/inet_1k_val_cls_pt.pkl'),\n",
    "                                 ('inet_r', '../resources/vit_s_embeddings/inet_r_cls_pt.pkl'),\n",
    "                                 ('inet_v2_70', '../resources/vit_s_embeddings/inet_v2_70_cls_pt.pkl'),\n",
    "                                 ('inet_v2_mf', '../resources/vit_s_embeddings/inet_v2_mf_cls_pt.pkl'),\n",
    "                                 ('inet_v2_top', '../resources/vit_s_embeddings/inet_v2_top_cls_pt.pkl')]:\n",
    "    \n",
    "    with open(loader_path, 'rb') as pkl_fl:\n",
    "        dataloaders_dict[loader_name] = torch.utils.data.DataLoader(dataset=DictionaryDataset(data=pickle.load(pkl_fl), index_list=inet_1k_labels), \n",
    "                                                   batch_size=128, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa0e3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_inet_c = dict()\n",
    "\n",
    "inet_c_embeds_src_path = '../resources/vit_s_embeddings/imagenet_c'\n",
    "inet_c_cor_types = os.listdir(inet_c_embeds_src_path)\n",
    "\n",
    "for cor_type in inet_c_cor_types:\n",
    "    for sev in range(1, 6):\n",
    "        with open(f'{inet_c_embeds_src_path}/{cor_type}/sev_{sev}.pkl', 'rb') as pkl_fl: \n",
    "            if sev == 1:\n",
    "                dataloaders_inet_c[cor_type] = dict()\n",
    "            dataloaders_inet_c[cor_type][sev] = torch.utils.data.DataLoader(dataset=DictionaryDataset(pickle.load(pkl_fl), inet_1k_labels), \n",
    "                                                           batch_size=128, shuffle=False, num_workers=8, pin_memory=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b57b6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions that return only required data per batch item which depends on the used pretrained head\n",
    "\n",
    "def cls_with_patch_one_layer(batch_samples: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.cat([torch.cat((batch_sample[1].squeeze(), batch_sample[0].squeeze())).unsqueeze(0)\n",
    "                                            for batch_sample in batch_samples])\n",
    "\n",
    "def cls_with_patch_one_layer_inet_c(batch_samples: torch.Tensor) -> torch.Tensor: \n",
    "    return torch.cat([torch.cat((batch_sample[1].squeeze(), batch_sample[0].squeeze())).unsqueeze(0) for batch_sample in batch_samples])\n",
    "\n",
    "def cls_without_patch_one_layer(batch_samples: torch.Tensor) -> torch.Tensor: \n",
    "    return torch.cat([batch_sample[1] for batch_sample in batch_samples])\n",
    "\n",
    "def cls_without_patch_one_layer_inet_c(batch_samples: torch.Tensor) -> torch.Tensor: \n",
    "    return torch.cat([batch_sample[1] for batch_sample in batch_samples])\n",
    "\n",
    "def cls_with_patch_four_layers(batch_samples: torch.Tensor) -> torch.Tensor: \n",
    "    return torch.cat([torch.cat(((torch.cat([cls_token for _, cls_token in batch_sample], dim=-1),\n",
    "                    batch_sample[3][0])), dim=-1)\n",
    "                    for batch_sample in batch_samples])\n",
    "\n",
    "# helper function \n",
    "# takes: model and list of dataloaders\n",
    "# returns: accuracy for each dataloader\n",
    "\n",
    "def calc_accuracy(model: torch.nn.Sequential, n_layers: int, with_patch: bool, dataloaders: list, is_inet_c_data: bool) -> list: \n",
    "\n",
    "    if n_layers == 1:\n",
    "        if with_patch:\n",
    "            sample_transform = cls_with_patch_one_layer \n",
    "            if is_inet_c_data:\n",
    "                sample_transform = cls_with_patch_one_layer_inet_c \n",
    "        else:\n",
    "            sample_transform = cls_without_patch_one_layer \n",
    "            if is_inet_c_data:\n",
    "                sample_transform = cls_without_patch_one_layer_inet_c\n",
    "    elif n_layers == 4: \n",
    "        sample_transform = cls_with_patch_four_layers \n",
    "\n",
    "    if sample_transform == None:\n",
    "        raise ValueError('SampleTransform function could not be defined')\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for dataloader in (pbar := tqdm(dataloaders, ncols=100)):\n",
    "                  \n",
    "        total_preds = 0\n",
    "        total_preds_true = 0\n",
    "        for batch_samples, batch_labels in dataloader: \n",
    "            batch_samples_dev = sample_transform(batch_samples).to(device)\n",
    "            \n",
    "            model_pred = model(batch_samples_dev).cpu()\n",
    "\n",
    "            is_equal = model_pred.argmax(axis=1) == batch_labels.argmax(axis=1)\n",
    "            total_preds += is_equal.shape[0]\n",
    "            total_preds_true += is_equal.type(torch.float).sum().item()\n",
    "\n",
    "        accuracies.append(total_preds_true / total_preds)\n",
    "\n",
    "    return accuracies \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "324a2fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearClassifier(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=1000, bias=True)\n",
       "    (1): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definition of linear classifiers \n",
    "\n",
    "model_params_one_layer = OrderedDict()\n",
    "model_params_four_layers = OrderedDict()\n",
    "model_params_cls_token = OrderedDict()\n",
    "model_params_one_layer['network.0.weight'] = pretr_head['weight']\n",
    "model_params_one_layer['network.0.bias'] = pretr_head['bias']\n",
    "model_params_cls_token['network.0.weight'] = pretr_head['weight'][:,0:384]\n",
    "model_params_cls_token['network.0.bias'] = pretr_head['bias']\n",
    "\n",
    "lc_one_layer = LinearClassifier(in_features=768, out_features=1000)\n",
    "lc_cls_token = LinearClassifier(in_features=384, out_features=1000)\n",
    "\n",
    "lc_one_layer.load_state_dict(model_params_one_layer)\n",
    "lc_cls_token.load_state_dict(model_params_cls_token)\n",
    "\n",
    "lc_one_layer.eval()\n",
    "lc_cls_token.eval()\n",
    "\n",
    "lc_one_layer.to(device)\n",
    "lc_cls_token.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdc4afd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 95/95 [06:55<00:00,  4.38s/it]\n",
      "100%|███████████████████████████████████████████████████████████████| 95/95 [07:38<00:00,  4.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculate acc for each Imagenet-C Val dataset \n",
    "\n",
    "for model, model_name, store_path in [(lc_cls_token, 'lc_cls', '../results/lc_cls_pretr_inet_c_res.pkl'),\n",
    "                          (lc_one_layer, 'lc_cls_patch', '../results/lc_one_lay_pretr_inet_c_res.pkl')]:\n",
    "    \n",
    "    inet_c_accuracies = dict()\n",
    "    inet_c_dloader_list = []\n",
    "\n",
    "    # list of dataloaders\n",
    "    for cor_type in dataloaders_inet_c.keys():\n",
    "        for sev in dataloaders_inet_c[cor_type].keys():\n",
    "            inet_c_dloader_list.append(dataloaders_inet_c[cor_type][sev])\n",
    "\n",
    "    # get list acc-vals, one acc-value for each of 95 INet-C datasets\n",
    "    if model_name == 'lc_cls':\n",
    "        inet_c_acc_list = calc_accuracy(model, 1, False, inet_c_dloader_list, is_inet_c_data=True)\n",
    "    else: \n",
    "        inet_c_acc_list = calc_accuracy(model, 1, True, inet_c_dloader_list, is_inet_c_data=True)\n",
    "\n",
    "    # map each acc-value to combination of (corruption type, severity)\n",
    "    acc_res_i = 0\n",
    "    for cor_type in dataloaders_inet_c.keys():\n",
    "        for sev in dataloaders_inet_c[cor_type].keys():\n",
    "            if sev == 1:\n",
    "                inet_c_accuracies[cor_type] = dict()\n",
    "            inet_c_accuracies[cor_type][sev] = inet_c_acc_list[acc_res_i]\n",
    "            acc_res_i += 1 \n",
    "\n",
    "    with open(store_path, 'wb') as pkl_fl:\n",
    "        pickle.dump(inet_c_accuracies, pkl_fl, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14aad00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dataset cor_type  sev          model      acc\n",
      "0  inet-c  spatter    1  lc_with_patch  0.78862\n",
      "1  inet-c  spatter    2  lc_with_patch  0.75822\n",
      "2  inet-c  spatter    3  lc_with_patch  0.71684\n",
      "3  inet-c  spatter    4  lc_with_patch  0.72546\n",
      "4  inet-c  spatter    5  lc_with_patch  0.67486\n",
      "  dataset cor_type  sev   model      acc\n",
      "0  inet-c  spatter    1  lc_cls  0.72488\n",
      "1  inet-c  spatter    2  lc_cls  0.69854\n",
      "2  inet-c  spatter    3  lc_cls  0.66492\n",
      "3  inet-c  spatter    4  lc_cls  0.66916\n",
      "4  inet-c  spatter    5  lc_cls  0.63050\n"
     ]
    }
   ],
   "source": [
    "# one DF with INet-C accuracies  \n",
    "\n",
    "inet_c_acc_dfs = dict()\n",
    "\n",
    "for model, load_path in [('lc_with_patch', '../results/lc_one_lay_pretr_inet_c_res.pkl'),\n",
    "              ('lc_cls', '../results/lc_cls_pretr_inet_c_res.pkl')]: \n",
    "    # load dict with acc of 95 Inet-C Datasets \n",
    "    with open(load_path, 'rb') as pkl_fl:\n",
    "        inet_c_acc_results = pickle.load(pkl_fl) \n",
    "\n",
    "    # create tuples with form: (dataset, cor, sev, model, acc)\n",
    "    inet_c_df_data = []\n",
    "    for cor_type in inet_c_acc_results.keys(): \n",
    "        for sev in inet_c_acc_results[cor_type].keys(): \n",
    "            acc = inet_c_acc_results[cor_type][sev]\n",
    "            inet_c_df_data.append(('inet-c', cor_type, sev, model, acc))\n",
    "\n",
    "    # create DF \n",
    "    inet_c_acc_dfs[model] = pd.DataFrame(data=inet_c_df_data, columns=['dataset', 'cor_type', 'sev', 'model', 'acc'])\n",
    "    print(inet_c_acc_dfs[model].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e15f00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     patch-acc   cls-acc       dataset\n",
      "sev                                   \n",
      "1     0.739889  0.677464  inet-c-sev-1\n",
      "2     0.673617  0.615355  inet-c-sev-2\n",
      "3     0.599676  0.548494  inet-c-sev-3\n",
      "4     0.497449  0.456148  inet-c-sev-4\n",
      "5     0.367285  0.338309  inet-c-sev-5\n"
     ]
    }
   ],
   "source": [
    "# bring inet-c-acc-DF in form (datasetname + sev, model-1-acc, model-2-acc)\n",
    "\n",
    "inet_c_avg_acc = inet_c_acc_dfs['lc_with_patch'].groupby(['sev'])[['acc']].mean()\n",
    "inet_c_avg_acc.rename({'acc': 'patch-acc'}, axis='columns', inplace=True)\n",
    "acc_cls = inet_c_acc_dfs['lc_cls'].groupby(['sev'])[['acc']].mean()\n",
    "inet_c_avg_acc['cls-acc'] = acc_cls['acc']\n",
    "inet_c_avg_acc = inet_c_avg_acc.assign(dataset= lambda x: x.index)\n",
    "inet_c_avg_acc['dataset'] = inet_c_avg_acc['dataset'].apply(lambda x: 'inet-c-sev-' + str(x))\n",
    "print(inet_c_avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "724c0231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate results for inet-r, inet-v2-70, inet-v2-mf, inet-v2-top \n",
    "\n",
    "ood_acc = dict() \n",
    "\n",
    "for model, model_name in [(lc_one_layer, 'lc_with_patch'), (lc_cls_token, 'lc_cls')]: \n",
    "    ood_acc[model_name] = dict()\n",
    "    for dname in dataloaders_dict.keys(): \n",
    "        if model_name == 'lc_with_patch':\n",
    "            ood_acc[model_name][dname] = calc_accuracy(model, 1, True, [dataloaders_dict[dname]], is_inet_c_data=False)[0]\n",
    "        else: \n",
    "            ood_acc[model_name][dname] = calc_accuracy(model, 1, False, [dataloaders_dict[dname]], is_inet_c_data=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef4a428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2299079/2315577759.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  acc_ood_df.rename(mapper={'acc': 'patch-acc'}, axis='columns', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# create DF for ood-acc-dict: (dset, model, acc)\n",
    "\n",
    "ood_acc_data = []\n",
    "for model_name in ood_acc.keys():\n",
    "    for dset_name in ood_acc[model_name].keys():\n",
    "        ood_acc_data.append((dset_name, model_name, ood_acc[model_name][dset_name]))\n",
    "\n",
    "ood_acc_df = pd.DataFrame(data=ood_acc_data, columns=['dataset', 'model', 'acc'])\n",
    "acc_with_patch = ood_acc_df.loc[ood_acc_df['model']=='lc_with_patch']\n",
    "acc_cls = ood_acc_df.loc[ood_acc_df['model']=='lc_cls']\n",
    "acc_cls = acc_cls.set_index([pd.Index([0, 1, 2, 3, 4])])\n",
    "acc_ood_df = acc_with_patch[['dataset', 'acc']]\n",
    "acc_ood_df.rename(mapper={'acc': 'patch-acc'}, axis='columns', inplace=True)\n",
    "acc_ood_df['cls-acc'] = acc_cls['acc']\n",
    "\n",
    "# concatenate inet-c results \n",
    "acc_ood_all = pd.concat([inet_c_avg_acc, acc_ood_df])\n",
    "acc_ood_all.to_csv('../results/ood_acc_results.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a2e5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6e0ab th {\n",
       "  font-size: 20px;\n",
       "  padding: 12px;\n",
       "}\n",
       "#T_6e0ab  td {\n",
       "  font-size: 20px;\n",
       "  padding: 12px;\n",
       "}\n",
       "#T_6e0ab th.col_heading.level0 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_6e0ab th.col_heading.level1 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_6e0ab th.col_heading.level1:2 {\n",
       "  border-right: 4px solid black;\n",
       "}\n",
       "#T_6e0ab td:3 {\n",
       "  border-right: 4px solid black;\n",
       "}\n",
       "#T_6e0ab_row0_col0, #T_6e0ab_row0_col2, #T_6e0ab_row8_col1, #T_6e0ab_row8_col4, #T_6e0ab_row8_col5 {\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row0_col1 {\n",
       "  background-color: #2e6e8e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row0_col3 {\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row0_col4 {\n",
       "  background-color: #7ad151;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row0_col5 {\n",
       "  background-color: #7cd250;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row1_col0 {\n",
       "  background-color: #c8e020;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row1_col1 {\n",
       "  background-color: #33638d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row1_col2 {\n",
       "  background-color: #54c568;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row1_col3 {\n",
       "  background-color: #3d4e8a;\n",
       "  color: #f1f1f1;\n",
       "  background-color: #65cb5e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row1_col4 {\n",
       "  background-color: #2fb47c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row1_col5 {\n",
       "  background-color: #32b67a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row2_col0 {\n",
       "  background-color: #5ac864;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row2_col1 {\n",
       "  background-color: #3c4f8a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row2_col2 {\n",
       "  background-color: #1f978b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row2_col3 {\n",
       "  background-color: #26828e;\n",
       "  color: #f1f1f1;\n",
       "  background-color: #1f9f88;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row2_col4 {\n",
       "  background-color: #218f8d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row2_col5 {\n",
       "  background-color: #21908d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row3_col0 {\n",
       "  background-color: #1f948c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row3_col1 {\n",
       "  background-color: #472f7d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row3_col2, #T_6e0ab_row3_col5 {\n",
       "  background-color: #375a8c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row3_col3 {\n",
       "  background-color: #40bd72;\n",
       "  color: #f1f1f1;\n",
       "  background-color: #34618d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row3_col4 {\n",
       "  background-color: #38598c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row4_col0 {\n",
       "  background-color: #433d84;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row4_col1, #T_6e0ab_row4_col2, #T_6e0ab_row4_col4, #T_6e0ab_row4_col5, #T_6e0ab_row5_col0 {\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row4_col3 {\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row5_col1 {\n",
       "  background-color: #39558c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row5_col2 {\n",
       "  background-color: #453781;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row5_col3 {\n",
       "  background-color: #75d054;\n",
       "  color: #000000;\n",
       "  background-color: #404688;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row5_col4 {\n",
       "  background-color: #404588;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row5_col5 {\n",
       "  background-color: #481f70;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6e0ab_row6_col0 {\n",
       "  background-color: #d0e11c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row6_col1 {\n",
       "  background-color: #f4e61e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row6_col2 {\n",
       "  background-color: #75d054;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row6_col3, #T_6e0ab_row8_col3 {\n",
       "  background-color: #46327e;\n",
       "  color: #f1f1f1;\n",
       "  background-color: #a0da39;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row6_col4 {\n",
       "  background-color: #cae11f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row6_col5 {\n",
       "  background-color: #cde11d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row7_col0 {\n",
       "  background-color: #b8de29;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row7_col1 {\n",
       "  background-color: #e2e418;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row7_col2 {\n",
       "  background-color: #65cb5e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row7_col3 {\n",
       "  background-color: #443b84;\n",
       "  color: #f1f1f1;\n",
       "  background-color: #8bd646;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row7_col4, #T_6e0ab_row7_col5 {\n",
       "  background-color: #6ccd5a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row8_col0 {\n",
       "  background-color: #d5e21a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6e0ab_row8_col2 {\n",
       "  background-color: #73d056;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6e0ab\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6e0ab_level0_col0\" class=\"col_heading level0 col0\" colspan=\"4\">Measure</th>\n",
       "      <th id=\"T_6e0ab_level0_col4\" class=\"col_heading level0 col4\" colspan=\"2\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_6e0ab_level1_col0\" class=\"col_heading level1 col0\" >C2 measure</th>\n",
       "      <th id=\"T_6e0ab_level1_col1\" class=\"col_heading level1 col1\" >C3 Measure</th>\n",
       "      <th id=\"T_6e0ab_level1_col2\" class=\"col_heading level1 col2\" >C1 Measure</th>\n",
       "      <th id=\"T_6e0ab_level1_col3\" class=\"col_heading level1 col3\" >L1 Measure</th>\n",
       "      <th id=\"T_6e0ab_level1_col4\" class=\"col_heading level1 col4\" >CLS</th>\n",
       "      <th id=\"T_6e0ab_level1_col5\" class=\"col_heading level1 col5\" >Patch + CLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6e0ab_level0_row0\" class=\"row_heading level0 row0\" >ImageNet-C-Sev-1</th>\n",
       "      <td id=\"T_6e0ab_row0_col0\" class=\"data row0 col0\" >0.990543</td>\n",
       "      <td id=\"T_6e0ab_row0_col1\" class=\"data row0 col1\" >0.174890</td>\n",
       "      <td id=\"T_6e0ab_row0_col2\" class=\"data row0 col2\" >0.768222</td>\n",
       "      <td id=\"T_6e0ab_row0_col3\" class=\"data row0 col3\" >193.900380</td>\n",
       "      <td id=\"T_6e0ab_row0_col4\" class=\"data row0 col4\" >0.677464</td>\n",
       "      <td id=\"T_6e0ab_row0_col5\" class=\"data row0 col5\" >0.739889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e0ab_level0_row1\" class=\"row_heading level0 row1\" >ImageNet-C-Sev-2</th>\n",
       "      <td id=\"T_6e0ab_row1_col0\" class=\"data row1 col0\" >0.975055</td>\n",
       "      <td id=\"T_6e0ab_row1_col1\" class=\"data row1 col1\" >0.169819</td>\n",
       "      <td id=\"T_6e0ab_row1_col2\" class=\"data row1 col2\" >0.702137</td>\n",
       "      <td id=\"T_6e0ab_row1_col3\" class=\"data row1 col3\" >261.050300</td>\n",
       "      <td id=\"T_6e0ab_row1_col4\" class=\"data row1 col4\" >0.615355</td>\n",
       "      <td id=\"T_6e0ab_row1_col5\" class=\"data row1 col5\" >0.673617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e0ab_level0_row2\" class=\"row_heading level0 row2\" >ImageNet-C-Sev-3</th>\n",
       "      <td id=\"T_6e0ab_row2_col0\" class=\"data row2 col0\" >0.943668</td>\n",
       "      <td id=\"T_6e0ab_row2_col1\" class=\"data row2 col1\" >0.160773</td>\n",
       "      <td id=\"T_6e0ab_row2_col2\" class=\"data row2 col2\" >0.651504</td>\n",
       "      <td id=\"T_6e0ab_row2_col3\" class=\"data row2 col3\" >318.244570</td>\n",
       "      <td id=\"T_6e0ab_row2_col4\" class=\"data row2 col4\" >0.548494</td>\n",
       "      <td id=\"T_6e0ab_row2_col5\" class=\"data row2 col5\" >0.599676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e0ab_level0_row3\" class=\"row_heading level0 row3\" >ImageNet-C-Sev-4</th>\n",
       "      <td id=\"T_6e0ab_row3_col0\" class=\"data row3 col0\" >0.901864</td>\n",
       "      <td id=\"T_6e0ab_row3_col1\" class=\"data row3 col1\" >0.147889</td>\n",
       "      <td id=\"T_6e0ab_row3_col2\" class=\"data row3 col2\" >0.589406</td>\n",
       "      <td id=\"T_6e0ab_row3_col3\" class=\"data row3 col3\" >390.715480</td>\n",
       "      <td id=\"T_6e0ab_row3_col4\" class=\"data row3 col4\" >0.456148</td>\n",
       "      <td id=\"T_6e0ab_row3_col5\" class=\"data row3 col5\" >0.497449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e0ab_level0_row4\" class=\"row_heading level0 row4\" >ImageNet-C-Sev-5</th>\n",
       "      <td id=\"T_6e0ab_row4_col0\" class=\"data row4 col0\" >0.839912</td>\n",
       "      <td id=\"T_6e0ab_row4_col1\" class=\"data row4 col1\" >0.131853</td>\n",
       "      <td id=\"T_6e0ab_row4_col2\" class=\"data row4 col2\" >0.520075</td>\n",
       "      <td id=\"T_6e0ab_row4_col3\" class=\"data row4 col3\" >478.030240</td>\n",
       "      <td id=\"T_6e0ab_row4_col4\" class=\"data row4 col4\" >0.338309</td>\n",
       "      <td id=\"T_6e0ab_row4_col5\" class=\"data row4 col5\" >0.367285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e0ab_level0_row5\" class=\"row_heading level0 row5\" >ImageNet-R</th>\n",
       "      <td id=\"T_6e0ab_row5_col0\" class=\"data row5 col0\" >0.807292</td>\n",
       "      <td id=\"T_6e0ab_row5_col1\" class=\"data row5 col1\" >0.163867</td>\n",
       "      <td id=\"T_6e0ab_row5_col2\" class=\"data row5 col2\" >0.559167</td>\n",
       "      <td id=\"T_6e0ab_row5_col3\" class=\"data row5 col3\" >418.948360</td>\n",
       "      <td id=\"T_6e0ab_row5_col4\" class=\"data row5 col4\" >0.424967</td>\n",
       "      <td id=\"T_6e0ab_row5_col5\" class=\"data row5 col5\" >0.406867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e0ab_level0_row6\" class=\"row_heading level0 row6\" >ImageNet-V2-70</th>\n",
       "      <td id=\"T_6e0ab_row6_col0\" class=\"data row6 col0\" >0.977057</td>\n",
       "      <td id=\"T_6e0ab_row6_col1\" class=\"data row6 col1\" >0.250456</td>\n",
       "      <td id=\"T_6e0ab_row6_col2\" class=\"data row6 col2\" >0.716523</td>\n",
       "      <td id=\"T_6e0ab_row6_col3\" class=\"data row6 col3\" >234.042130</td>\n",
       "      <td id=\"T_6e0ab_row6_col4\" class=\"data row6 col4\" >0.729400</td>\n",
       "      <td id=\"T_6e0ab_row6_col5\" class=\"data row6 col5\" >0.796800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e0ab_level0_row7\" class=\"row_heading level0 row7\" >ImageNet-V2-MF</th>\n",
       "      <td id=\"T_6e0ab_row7_col0\" class=\"data row7 col0\" >0.970768</td>\n",
       "      <td id=\"T_6e0ab_row7_col1\" class=\"data row7 col1\" >0.246940</td>\n",
       "      <td id=\"T_6e0ab_row7_col2\" class=\"data row7 col2\" >0.709310</td>\n",
       "      <td id=\"T_6e0ab_row7_col3\" class=\"data row7 col3\" >243.696440</td>\n",
       "      <td id=\"T_6e0ab_row7_col4\" class=\"data row7 col4\" >0.668700</td>\n",
       "      <td id=\"T_6e0ab_row7_col5\" class=\"data row7 col5\" >0.727400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e0ab_level0_row8\" class=\"row_heading level0 row8\" >ImageNet-V2-TOP</th>\n",
       "      <td id=\"T_6e0ab_row8_col0\" class=\"data row8 col0\" >0.978815</td>\n",
       "      <td id=\"T_6e0ab_row8_col1\" class=\"data row8 col1\" >0.252565</td>\n",
       "      <td id=\"T_6e0ab_row8_col2\" class=\"data row8 col2\" >0.715221</td>\n",
       "      <td id=\"T_6e0ab_row8_col3\" class=\"data row8 col3\" >234.846040</td>\n",
       "      <td id=\"T_6e0ab_row8_col4\" class=\"data row8 col4\" >0.763500</td>\n",
       "      <td id=\"T_6e0ab_row8_col5\" class=\"data row8 col5\" >0.832400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d08fab5e4b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine avg measure values with accuracy values of linear classifier \n",
    "\n",
    "map_dname = {'inet-c-sev-1': 'inet_c_sev_1', 'inet-c-sev-2': 'inet_c_sev_2', 'inet-c-sev-3': 'inet_c_sev_3', 'inet-c-sev-4': 'inet_c_sev_4',\n",
    "             'inet-c-sev-5': 'inet_c_sev_5', 'inet_r': 'inet_r', 'inet_v2_70': 'inet_v2_70', 'inet_v2_mf': 'inet_v2_mf', ''\n",
    "             'inet_v2_top': 'inet_v2_top'}\n",
    "\n",
    "ood_acc_df = pd.read_csv('../results/ood_acc_results.csv', sep=';')\n",
    "avg_measure_all = pd.read_csv('../results/class_statistics_avg_results.csv', sep=';')\n",
    "\n",
    "avg_measure_all.set_index(avg_measure_all['dataset'], inplace=True)\n",
    "\n",
    "ood_acc_df = ood_acc_df.loc[ood_acc_df['dataset'] != 'inet_1k_val']\n",
    "ood_acc_df['dataset'] = ood_acc_df.apply(lambda x: map_dname[x['dataset']], axis=1)\n",
    "ood_acc_df.set_index(ood_acc_df['dataset'], inplace=True)\n",
    "ood_acc_df.drop('Unnamed: 0', axis='columns', inplace=True)\n",
    "\n",
    "ood_acc_and_measures_df = pd.concat([ood_acc_df, avg_measure_all], axis=1)\n",
    "ood_acc_and_measures_df.drop('dataset', axis=1, inplace=True)\n",
    "\n",
    "ood_acc_and_measures_df['CLS'] = ood_acc_and_measures_df['cls-acc']\n",
    "ood_acc_and_measures_df['Patch + CLS'] = ood_acc_and_measures_df['patch-acc']\n",
    "ood_acc_and_measures_df.drop('patch-acc', axis=1, inplace=True)\n",
    "ood_acc_and_measures_df.drop('cls-acc', axis=1, inplace=True)\n",
    "ood_acc_and_measures_df.rename({ 'c2': 'C2 measure', 'c3': 'C3 Measure', 'c1': 'C1 Measure', 'l1_measure': 'L1 Measure'},\n",
    "                               inplace=True, axis=1)\n",
    "\n",
    "col_old = ood_acc_and_measures_df.columns\n",
    "ood_acc_and_measures_df.set_index(pd.Index(['ImageNet-C-Sev-1', 'ImageNet-C-Sev-2', 'ImageNet-C-Sev-3', 'ImageNet-C-Sev-4', 'ImageNet-C-Sev-5',\n",
    "                                            'ImageNet-R', 'ImageNet-V2-70', 'ImageNet-V2-MF', 'ImageNet-V2-TOP']), inplace=True)\n",
    "ood_acc_and_measures_df.columns = pd.MultiIndex.from_tuples([\n",
    "    ('Measure', col_old[0]),\n",
    "    ('Measure', col_old[1]),\n",
    "    ('Measure', col_old[2]),\n",
    "    ('Measure', col_old[3]),\n",
    "    ('Accuracy', col_old[4]), \n",
    "    ('Accuracy', col_old[5])])\n",
    "\n",
    "# create table with background colour of cell indicating the value rank\n",
    "with open('/home/stud/afroehli/coding/dinov2_ood/diagrams/ood_acc_and_measures.tex', 'w') as latex_table:\n",
    "    ood_acc_and_measures_df.style.background_gradient(cmap='viridis').background_gradient(cmap='viridis_r', subset=[('Measure', 'L1 Measure')]).set_table_styles([\n",
    "        {\"selector\": \"th, td\", \"props\": [(\"font-size\", \"20px\"), (\"padding\", \"12px\")]},\n",
    "        {'selector': 'th.col_heading.level0', 'props': [('text-align', 'center')]},\n",
    "        {'selector': 'th.col_heading.level1', 'props': [('text-align', 'center')]},\n",
    "        {\n",
    "            'selector': 'th.col_heading.level1:2',\n",
    "            'props': [('border-right', '4px solid black')]\n",
    "        },\n",
    "        {\n",
    "            'selector': 'td:3',\n",
    "            'props': [('border-right', '4px solid black')]\n",
    "        }\n",
    "    ]).to_latex(latex_table)\n",
    "\n",
    "ood_acc_and_measures_df.style.background_gradient(cmap='viridis').background_gradient(cmap='viridis_r', subset=[('Measure', 'L1 Measure')]).set_table_styles([\n",
    "        {\"selector\": \"th, td\", \"props\": [(\"font-size\", \"20px\"), (\"padding\", \"12px\")]},\n",
    "        {'selector': 'th.col_heading.level0', 'props': [('text-align', 'center')]},\n",
    "        {'selector': 'th.col_heading.level1', 'props': [('text-align', 'center')]},\n",
    "        {\n",
    "            'selector': 'th.col_heading.level1:2',\n",
    "            'props': [('border-right', '4px solid black')]\n",
    "        },\n",
    "        {\n",
    "            'selector': 'td:3',\n",
    "            'props': [('border-right', '4px solid black')]\n",
    "        }\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2Pre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
